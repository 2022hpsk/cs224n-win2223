# <p align="center">CS224N: Natural Language Processing with Deep Learning</p>
## <p align="center">[Stanford / Winter 2023](http://web.stanford.edu/class/cs224n/index.html)</p>
Walkthrough of the schedule and solutions of the assignments of the Stanford CS224N: Natural Language Processing with Deep Learning course from winter 2022/23

Reading papers is an important part of this course and crucial for completing the assignments. Therefore I recommend to have a look at [How to read a Paper](https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf)

## My Schedule

**Apr.18.2023**
- watch [Lecture 1](https://youtu.be/rmVRLeJRkl4) and [Lecture 2](https://youtu.be/gqaHkPEZAew)
- read [Efficient Estimation of Word Representations in Vector Space](http://arxiv.org/pdf/1301.3781.pdf) and [Distributed Representations of Words and Phrases and their Compositionality](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)
- finish [assignment 1](https://github.com/floriankark/cs224n-win2223/tree/main/a1)
- go through [Python Review Session](https://colab.research.google.com/drive/1hxWtr98jXqRDs_rZLZcEmX_hUcpDLq6e?usp=sharing) ([slides](http://web.stanford.edu/class/cs224n/readings/cs224n-python-review-2023.pdf))
 
 **Apr.19.2023**
- read [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf), [Improving Distributional Similarity with Lessons Learned from Word Embeddings](http://www.aclweb.org/anthology/Q15-1016) and [Evaluation methods for unsupervised word embeddings](http://www.aclweb.org/anthology/D15-1036)
- watch [Lecture 3](https://youtu.be/X0Jw4kgaFlg) and [Lecture 4](https://youtu.be/PSGIodTN3KE)

 **Apr.20.2023**
- read [matrix calculus notes](http://web.stanford.edu/class/cs224n/readings/gradient-notes.pdf), [Review of differential calculus](http://web.stanford.edu/class/cs224n/readings/review-differential-calculus.pdf), [CS231n notes on network architectures](http://cs231n.github.io/neural-networks-1/), [CS231n notes on backprop](http://cs231n.github.io/optimization-2/), [Derivatives, Backpropagation, and Vectorization](http://cs231n.stanford.edu/handouts/derivatives.pdf) and [Learning Representations by Backpropagating Errors](http://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf)
